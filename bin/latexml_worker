#!/usr/bin/perl -w
#################################
# A ZeroMQ worker for CorTeX    #
#  TeX-to-HTML5 conversions     #
#  via LaTeXML                  #
#################################

# Created and provided by Deyan Ginev
#   released in the Public Domain

### 
# Explanation: The goal here is to stay "safe" in the following aspects:
# - RAM allocation for CorTeX I/O - some jobs in arXiv are >1GB. Hence we stream both input and output into RAMdisk tempfiles.
# - RAM allocation for LaTeXML - Perl's garbage collector dangerously takes its time with certain structures, deallocating only at
#     process termination. To ensure deallocation, while also benefiting from the daemonization speedups, we do a Perl fork() for each latexml job.
# - Rogue infinite loops / busy malfunctions: arXiv has certain image files that send "convert" and "gs" for a loop, turning latexml unresponsive.
#     To counteract these we use: 
#     1) a separate process to observe the timeout (as even alarm() can't fire in some blocked cases!)
#     2) The 9 kill signal (only fire seemed to work)
#     3) The occasional worker restart, every 100 jobs or so.
# We pay a price here - fork() is an expensive op, however that is worth the price in order to ensure memory safety.

use ZMQ::LibZMQ3;
use ZMQ::Constants qw(ZMQ_DEALER ZMQ_PUSH ZMQ_SNDMORE ZMQ_RCVMORE ZMQ_IDENTITY);
use File::Temp qw(tempfile);
use File::Find;
use Archive::Zip qw(:CONSTANTS :ERROR_CODES);

# Obtain the path of this executable, for easy restart.
use FindBin;
my $RealBin_safe;
BEGIN {
  $FindBin::RealBin =~ /^([^\0]+)\z/; # Valid Unix path TODO: Windows, revisit regexp
  $RealBin_safe = $1;
  die 'Fatal:IO:tainted RealBin was tainted! Failing...'
   unless ($RealBin_safe && (-e $RealBin_safe.'/latexml_worker')); 
}


# Set up basic parameters for this CorTeX service
my $service_name = 'tex_to_html';
my $message_size = 100000;
my $work_counter = 0;
my $identity = join('',map { (q(a)..q(z))[rand(26)] } 1 .. 20);
my $timeout_limit = 1200; # If worker isn't done in 20 minutes - timeout
my $m_timeout_limit = 2 * $timeout_limit/(24 * 60 * 60); # Twice the timeout is what we allow files to live on the ramdisk
# We also provide defaults for certain defensive environmental variables, if not yet set
#  in particular, for LaTeXML's ImageMagick conversion jobs.
#  pending review at: https://github.com/brucemiller/LaTeXML/pull/666
$ENV{MAGICK_DISK_LIMIT} = "2GiB" unless defined $ENV{MAGICK_DISK_LIMIT};
$ENV{MAGICK_MEMORY_LIMIT} = "512MiB" unless defined $ENV{MAGICK_MEMORY_LIMIT};
$ENV{MAGICK_MAP_LIMIT} = "1GiB" unless defined $ENV{MAGICK_MAP_LIMIT};
$ENV{MAGICK_TIME_LIMIT} = "300" unless defined $ENV{MAGICK_TIME_LIMIT};
# No excuses - use the RAM disk
$ENV{TMPDIR}='/dev/shm';
$min_memory_needed = 102400; # 100MB for now

# Set up the cortex endpoints
my $cortex_ip = shift || '212.201.49.37';
my $cortex_ventilator_port = shift || '5555';
my $cortex_sink_port = shift || '5556';
my $ventilator_address = "tcp://$cortex_ip:$cortex_ventilator_port";
my $sink_address = "tcp://$cortex_ip:$cortex_sink_port";

# Connect to a task ventilator
my $ventilator_context = zmq_init;
my $ventilator = zmq_socket( $ventilator_context, ZMQ_DEALER );
zmq_setsockopt($ventilator, ZMQ_IDENTITY, $identity);
zmq_connect($ventilator, $ventilator_address);

# Connect to a task sink
my $sink_context = zmq_init;
my $sink = zmq_socket( $sink_context, ZMQ_PUSH );
zmq_connect($sink, $sink_address);

# Work in perpetuity
print STDERR "-- [$$] Worker $identity started\n";
my $taskid_msg = zmq_msg_init();
my $recv_msg = zmq_msg_init();
while (1) {
  # Before each job, ensure we have space sanity in the scratch tmpdir we are using
  my @parts = split(/\s+/,`df $ENV{TMPDIR}`); # modern Linux only for now, maybe improve later?
  my $free_mem = $parts[10] || 0;
  if ($free_mem < $min_memory_needed) {
    print STDERR "-- [$$] Free memory is $free_mem, insufficient. Will try to clean up.\n";
    local $\ = "\n";
    my @entries = map {chomp; $_} `ls $ENV{TMPDIR}`;
    foreach $name(@entries) {
      my $entry = "$ENV{TMPDIR}/$name";
      if (-e $entry && (-M $entry > $m_timeout_limit)) {
        print STDERR "Deleting old entry: $entry";
        `rm -rf $entry`;
      }
    }
    # Recheck the free memory
    @parts = split(/\s+/,`df $ENV{TMPDIR}`); # modern Linux only for now, maybe improve later?
    $free_mem = $parts[10] || 0;
    # If it is still insufficient, sleep for a minute, then retry
    if ($free_mem < $min_memory_needed) {
      print STDERR "-- [$$] Free memory is now $free_mem, still insufficient. Sleeping for a minute.\n";
      sleep 60;
      next;
    } else {
      print STDERR "-- [$$] Free memory is now $free_mem, looks good. Proceeding to work.\n";
    }
  }

  # Throttle by default, we will only accept an immediate next job if it looks like we've sent actual data back to the sink
  #  (avoids unpleasant+uncaught edge cases where the reader continues on without performing any work.)
  my $mem_allowance = $free_mem;
  print STDERR "Current mem_allowance: $mem_allowance\n";
  my $mem_guard = 0; # Guard for out-of-memory issues.
  my $throttle_guard = 1;
  ### There is no clear reason why we would want to restart the process, in fact restarting it makes us lose the pid for latexml_harness, and causes an unwanted disconnect
  #### restart_worker('job limit', $cortex_ip, $cortex_ventilator_port, $cortex_sink_port) if $work_counter > 100; # Respawn every 100 jobs, just to stay safe.
  
  # First, request a task from the ventilator  
  zmq_sendmsg( $ventilator, $service_name );
  print STDERR "-- [$$] Waiting for jobs\n";
  my $rv = zmq_msg_recv($taskid_msg, $ventilator, 0);
  my $taskid = zmq_msg_data($taskid_msg);
  print STDERR "-- [$$] Job found, receiving taskid #$taskid.\n";
  
  # Prepare a File for the input: we want a temp file, on a RAM disk (/dev/shm), without auto-remove
  my ($input_fh, $input_filepath) = tempfile($taskid."_inXXXX", SUFFIX => ".zip", TMPDIR=>1, UNLINK => 0);
  my ($output_fh, $output_filepath) = tempfile($taskid."_outXXXX", SUFFIX => ".zip", TMPDIR=>1, UNLINK => 0);
  close $output_fh;
  binmode($input_fh);
  my $input_size = 0;
  while (1) {
    my $received = zmq_msg_recv($recv_msg, $ventilator, ZMQ_RCVMORE);
    last unless $received > 0;

    $input_size += $received;
    $mem_allowance -= $received;
    if ($mem_allowance > 0) {
      print $input_fh zmq_msg_data($recv_msg);
    } else {
      zmq_msg_data($recv_msg);
      $mem_guard = 1;
    }
  }
  close $input_fh;
  # If the remaining memory allowance is less than half the free memory measured at the start of receiving, 
  # there is a high chance the output won't fit the disk; this is conservative on the side of safety
  if ($mem_allowance < ($free_mem / 2)) {  $mem_guard = 1; }
  if ($mem_guard) {
    print STDERR "-- [$$] Taskid #$taskid could not start conversion, mem_guard triggered.\n";  
    # Clean up, then move on, we can't work on this task.
    unlink($input_filepath);
    unlink($output_filepath);
    next;
  }
  
  $work_counter++;
  print STDERR "-- [$$] Taskid #$taskid received, converting...\n";

  my $is_converted = ($input_size > 0) && convert($taskid, $input_filepath, $output_filepath);
  print STDERR "-- [$$] Conversion #$work_counter complete.\n";
  # Let sink know a result is incoming
  print STDERR "-- [$$] Responding to sink with $taskid result...\n";
  zmq_sendmsg( $sink, $service_name, ZMQ_SNDMORE);
  zmq_sendmsg( $sink, $taskid, ZMQ_SNDMORE);
  # Did the conversion succeed? Determine response based on that.
  if ($is_converted) {
    open($output_fh, "<", $output_filepath);
    binmode($output_fh);
    # Stream converted data via zmq
    #  Read file in $message_size blocks
    my $data_buffer = '';
    while (my $size = read($output_fh, $data_buffer, $message_size)) {
      if ($size > 0) { $throttle_guard = 0; } # disable throttle if we've sent back data
      if ($size < $message_size) {
        # Last message
        zmq_send($sink, $data_buffer, $size, 0);
      } else {
        # Message part, more will follow
        zmq_send($sink,$data_buffer,$size, ZMQ_SNDMORE);
      }
      $data_buffer = '';
    }
    close $output_fh;
    # And the job is done.
    if (!$throttle_guard) {
      print STDERR "-- [$$] CorTeX task #$taskid (worker job $work_counter) completed.\n";
    } else {
      print STDERR "-- [$$] CorTeX task #$taskid (worker job $work_counter) failed.\n"; 
    }
  }
  else {
    # Conversion failed, send an empty result body
    zmq_send($sink, '', 0, 0);
    print STDERR "-- [$$] CorTeX task #$taskid (worker job $work_counter) failed.\n"; 
  }
  # Time to remove our temp files
  unlink($input_filepath);
  unlink($output_filepath);
  if ($throttle_guard) {
    print STDERR "-- [$$] CorTeX task #$taskid (worker job $work_counter) did not return data to sink, throttling (1 minute sleep).\n";
    sleep 60;
  }
}

sub convert {
  my ($taskid, $source, $destination) = @_;
  my $log_filepath = "cortex.log";
  ### SPAWN a new LaTeXML process here, we are entering unsafe territory
  my $pid = fork();
  die if not defined $pid; # Error-handling
  ###
  # 1. PARENT
  if ($pid) {
    # Simply wait for the child to terminate and return:
    return waitpid($pid, 0); 
  }
  ###
  # 1. CHILD
  else {
    # Group leader, so that we can timeout the entire process group
    setpgrp(0, 0);
    # External timer to prevent problems in system calls
    #    20 seconds extra, so that the latexml timeout has theoretical chance to get registered and reported back successfully
    my $timer_pid = with_external_timer($timeout_limit + 20);
    # CorTeX workhorses have lowest priority, to avoid overloading the machine
    setpriority(0, $$, 20);

    # Load as late as possible, to optimize runtime
    use LaTeXML;
    use LaTeXML::Common::Config;
    # Set up conversion parameters for LaTeXML
    my $conversion_opts=LaTeXML::Common::Config->new(local=>1,whatsin=>'archive',whatsout=>'archive',
      format=>'html5',mathparse=>'RecDescent',post=>1,math_formats=>['pmml','cmml'],
      preload=>['[ids]latexml.sty'],css=>['http://latexml.mathweb.org/css/external/LaTeXML.css'],
      defaultresources=>0,inputencoding=>'iso-8859-1',timeout=>$timeout_limit,
      log=>$log_filepath);
    $conversion_opts->check;
    my $converter = LaTeXML->get_converter($conversion_opts);
    # Actual latexml conversion happens here.
    $converter->prepare_session($conversion_opts);
    my $response = $converter->convert($source);
    reset_external_timer($timer_pid); # Reset external timer 
    # This is a little silly -> the LaTeXML API does not (yet?) support direct local writing of Archives.
    # In other words, the final Archive is contained into $response - a potentially huge variable. 
    # In any case, let's write that variable into the needed destination:
    my $output_handle;
    if (!($response->{result} && open($output_handle, ">", $destination))) {
      $fail_archive = Archive::Zip->new();
      my $log_text = $response->{log} || "Fatal:unknown:empty_output\nStatus:conversion:3";
      $fail_archive->addString("$log_text",$log_filepath);
      exit ($fail_archive->writeToFileNamed($destination) == AZ_OK); }
    else {
      binmode($output_handle);
      my $print_ok = print $output_handle $response->{result};
      close $output_handle;
      exit $print_ok; } 
    # This convert process is a one-time job, ending here.
    exit 0; 
  }
}

### Utilities
# Restart support for keeping the worker operational over long inactivity periods
sub restart_worker {
  my ($reason,$cortex_ip, $cortex_ventilator_port, $cortex_sink_port) = @_;
  print STDERR "[".localtime()."] [$$] $reason reached, restarting\n";
  exec("$RealBin_safe/latexml_worker",$cortex_ip, $cortex_ventilator_port, $cortex_sink_port)
    or die("Fatal:latexml_worker:restart Worker $$ autoflush Failed!"); }

sub with_external_timer {
  my ($time) = @_;
  my $parent = $$;
  my $pid = fork();
  return $pid if $pid; # If parent finishes normally, it will kill $pid
  sleep $time; # Sleep for the timeout

  # Core timeout handler:
  # If we haven't been killed, there is a system call timeout => kill the parent
  print STDERR "[".localtime()."] [$$] Killing $parent via external timeout\n";
  # Record the failure:
  # $job->fail('Fatal:latexml_worker:timeout [$identity] Worker timed out after $time seconds.');
  # We really need KILL here, the "gs" infinite loop from LaTeXML can't be killed in any other way
  kill -9, getpgrp($$);
  # And exit;
  exit 0; }

sub reset_external_timer {
  my ($pid) = @_;
  kill 'KILL', $pid;
  return; }

1;